{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WFC3 Guide Star Failure Classification Using Convolutional Neural Networks (CNNs)\n",
    "---\n",
    "The purpose of this notebook is to demosnstrate how to use a DeepWFC3 machine learning model to identify if a WFC3 image is affected by a guide star failure (GS fail). The models presented here are fully described in the [WFC3 ISR 2024-03](https://www.stsci.edu/files/live/sites/www/files/home/hst/instrumentation/wfc3/documentation/instrument-science-reports-isrs/_documents/2024/WFC3-ISR-2024-03.pdf).\n",
    "\n",
    "## Imports\n",
    "\n",
    "If you are running this notebook in Jupyter, this notebook assumes you created the virtual environment defined in environment.yml. If not, close this notebook and run the following lines in a terminal window:\n",
    "\n",
    "```\n",
    "conda env create -f environment.yml\n",
    "conda activate deepwfc3_env\n",
    "```\n",
    "\n",
    "We import the following libraries:\n",
    "\n",
    "- `os` for handling paths\n",
    "- `glob` for querying directories\n",
    "- `numpy` for handling arrays\n",
    "- `pandas` for handling dataframes\n",
    "- `matplotlib` for plotting\n",
    "- `astropy` for handling astronomical data\n",
    "- `astroquery` for downloading astronomical data\n",
    "- `ginga` for image scaling\n",
    "- `torch` as our machine learning framework\n",
    "\n",
    "We also import `data_process` for data reduction tasks and `model` to load the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astroquery.mast import Observations\n",
    "from ginga.util.zscale import zscale\n",
    "\n",
    "# Machine learning module\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Data processing and augmentation module\n",
    "import data_process\n",
    "\n",
    "# Model module\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Example Data\n",
    "\n",
    "We start by downloading some sample images from the MAST database, using `astroquery`, that are examples of nominal and GS fail images.\n",
    "\n",
    "The rootnames of the guide star failures are:\n",
    "- ied203fqq\n",
    "- ie9m0xv1q\n",
    "- ieou18fkq\n",
    "\n",
    "The nominal images are:\n",
    "- iec39axmq\n",
    "- ientf1gjq\n",
    "- ie3b36n5q\n",
    "- ie3b40ljq\n",
    "\n",
    "First, we get a table of the fits files with the image data that we are interested in to make sure that we are downloading the correct files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDs and rootnames of the example images we'll download\n",
    "example_IDs = ['ied203*', 'ie9m0x020', 'ieou18020','iec39a010', 'ientf1010', 'ie3b36010', 'ie3b40010']\n",
    "rootnames = ['ied203fqq', 'ie9m0xv1q', 'ieou18fkq', 'iec39axmq', 'ientf1gjq', 'ie3b36n5q', 'ie3b40ljq']\n",
    "\n",
    "example_query = Observations.query_criteria(obs_id=example_IDs)\n",
    "example_prods = Observations.get_product_list(example_query)\n",
    "example_table = Observations.filter_products(example_prods, obs_id=rootnames, extension=['_flt.fits'])\n",
    "example_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have confirmed that the files in the table are the correct images, and that the correct number of them are in the table (7), we download them from MAST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the images we want to use\n",
    "downloads = Observations.download_products(example_table, mrp_only=False, cache=False)\n",
    "\n",
    "downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process and augment the images\n",
    "\n",
    "Next, we process and augment the downlaoded example images using `data_process`. The function `log_data_process` performs the following procedure:\n",
    "* Opens the SCI array of the `flt.fits` file as an array.\n",
    "* Sets all values in the image array that are less than one to be equal to 1.\n",
    "* Scales the image data logarithmically.\n",
    "* Resizes the image array to the dimensions (256, 256).\n",
    "* Uses min/max scaling to scale the pixel values to be between 0 and 1.\n",
    "\n",
    "The function `augment` creates an augmented copy of the processed image by:\n",
    "* Vertically flipping the image with a 50% probability.\n",
    "* Horizontally flipping the image with a 50% probability.\n",
    "* Rotating the image to a random degree of (0,360).\n",
    "* Cropping the image in the center to be (180,180)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists of images and rootnames\n",
    "original_images = []\n",
    "processed_images = []\n",
    "augmented_images = []\n",
    "root = []\n",
    "\n",
    "# Process the images\n",
    "for i in range(0, len(downloads['Local Path'])):\n",
    "    # Get the processed and original version of the image\n",
    "    proc_image, orig_image = data_process.log_image_process(downloads['Local Path'][i], True)\n",
    "    processed_images.append(proc_image)\n",
    "    original_images.append(orig_image)\n",
    "    \n",
    "    # Get an augmented version of the image\n",
    "    aug_image = data_process.augment(proc_image)\n",
    "    augmented_images.append(aug_image)\n",
    "    \n",
    "    # Get ordered list of rootnames for later\n",
    "    base = os.path.basename(downloads['Local Path'][i])\n",
    "    root.append(base.split('_')[0])\n",
    "\n",
    "# Convert lists to arrays\n",
    "proc_examples = np.array(processed_images)\n",
    "aug_examples = np.array(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the processed and augmented images, we look at the difference between the original, processed, and augmented images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the number to look at different images in the set\n",
    "img = 1\n",
    "vmin, vmax = zscale(original_images[img])\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=[20,30])\n",
    "# Plot the unprocessed image\n",
    "axs[0].set_title('Original image (Zscaled)')\n",
    "A = axs[0].imshow(original_images[img], vmin=vmin, vmax=vmax, cmap='gray', origin='lower')\n",
    "fig.colorbar(A, ax=axs[0], shrink=0.15)\n",
    "\n",
    "# Plot the processed image\n",
    "axs[1].set_title('Processed image')\n",
    "B = axs[1].imshow(processed_images[img], cmap='gray', origin='lower')\n",
    "fig.colorbar(B, ax=axs[1], shrink=0.15)\n",
    "\n",
    "# Plot the augmented image\n",
    "axs[2].set_title('Augmented image')\n",
    "C = axs[2].imshow(augmented_images[img], cmap='gray', origin='lower')\n",
    "fig.colorbar(C, ax=axs[2], shrink=0.15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the models\n",
    "\n",
    "Next, we load the model parameters and achitectures, and set them to evaluation mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model parameters\n",
    "param_files = sorted(glob.glob('model_params/*.pt'))\n",
    "\n",
    "param_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the models:\n",
    "model1 = Model(sub_array_size=256)\n",
    "model1.load_state_dict(torch.load(param_files[0]))\n",
    "model1.eval();\n",
    "\n",
    "model2 = Model(sub_array_size=180)\n",
    "model2.load_state_dict(torch.load(param_files[1]))\n",
    "model2.eval();\n",
    "\n",
    "model3 = Model(sub_array_size=256)\n",
    "model3.load_state_dict(torch.load(param_files[2]))\n",
    "model3.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions image classifications\n",
    "\n",
    "Now, we classify the images with the models. We also define a function `softmax` to convert output neuron activations to probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define softmax for getting prediction probs\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 predictions\n",
    "model1_out = model1(torch.Tensor(proc_examples.reshape(proc_examples.shape[0], 1, proc_examples.shape[1], proc_examples.shape[1])))\n",
    "model1_preds = np.argmax(model1_out.detach().numpy(),axis=1)\n",
    "model1_pred_probs = np.max((softmax(model1_out)).detach().numpy(),axis=1)\n",
    "\n",
    "# Model 2 predictions\n",
    "model2_out = model2(torch.Tensor(aug_examples.reshape(aug_examples.shape[0], 1, aug_examples.shape[1], aug_examples.shape[1])))\n",
    "model2_preds = np.argmax(model2_out.detach().numpy(),axis=1)\n",
    "model2_pred_probs = np.max((softmax(model2_out)).detach().numpy(),axis=1)\n",
    "\n",
    "# Model 3 predictions\n",
    "model3_out = model3(torch.Tensor(proc_examples.reshape(proc_examples.shape[0], 1, proc_examples.shape[1], proc_examples.shape[1])))\n",
    "model3_preds = np.argmax(model3_out.detach().numpy(),axis=1)\n",
    "model3_pred_probs = np.max((softmax(model3_out)).detach().numpy(),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate predictions\n",
    "\n",
    "We compare our model predictions and probabilities with the actual classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe columns\n",
    "col_names = [\n",
    "    'Example Rootname', 'Correct Prediction', \n",
    "    'Model 1 Prediction', 'Model 1 Probability',\n",
    "    'Model 2 Prediction', 'Model 2 Probability',\n",
    "    'Model 3 Prediction', 'Model 3 Probability'\n",
    "]\n",
    "\n",
    "# Corrent predictions\n",
    "correct_preds = [1, 0, 1, 0, 0, 0, 1]\n",
    "\n",
    "# Make dictionary\n",
    "all_data = {'Example Rootname': root,\n",
    "            'Correct Prediction':correct_preds,\n",
    "            'Model 1 Prediction':model1_preds,\n",
    "            'Model 1 Prediction Probability':model1_pred_probs,\n",
    "            'Model 2 Prediction':model2_preds,\n",
    "            'Model 2 Prediction Probability':model2_pred_probs,\n",
    "            'Model 3 Prediction':model3_preds,\n",
    "            'Model 3 Prediction Probability':model3_pred_probs\n",
    "}\n",
    "\n",
    "# Create dataframe from dictionary\n",
    "pred_table = pd.DataFrame(all_data)\n",
    "pred_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the models predicted the images correctly with high probabilities for their predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Thank you for walking through this notebook. Now you should be more familiar with using our models to predict if WFC3 images are affected by guide star failures.\n",
    "\n",
    "## About this Notebook\n",
    "\n",
    "Authors: Megan Jones, Fred Dauphin, DeepHST\n",
    "\n",
    "Created on: 2024-04-29\n",
    "\n",
    "Updated on: 2024-11-23\n",
    "\n",
    "## Citations\n",
    "\n",
    "If you use `numpy`, `matplotlib`, `pandas`, `astropy`, `astroquery`, or `torch` for published research, please cite the authors. Follow these links for more information about citing `numpy`, `matplotlib`, `pandas`, `astropy`, `astroquery`, and `torch`:\n",
    "\n",
    "- Citing [`numpy`](https://numpy.org/citing-numpy/)\n",
    "- Citing [`matplotlib`](https://matplotlib.org/stable/project/citing.html)\n",
    "- Citing [`pandas`](https://pandas.pydata.org/about/citing.html)\n",
    "- Citing [`astropy`](https://www.astropy.org/acknowledging.html)\n",
    "- Citing [`astroquery`](https://github.com/astropy/astroquery/blob/main/astroquery/CITATION)\n",
    "- Citing [`torch`](https://arxiv.org/abs/1912.01703)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

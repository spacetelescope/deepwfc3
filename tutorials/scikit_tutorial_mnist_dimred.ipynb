{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction using PCA, t-SNE, and UMAP <a id=\"title\"></a>\n",
    "\n",
    "This notebook assumes you are familiar with basic machine learning vocabulary.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "[Introduction](#intro) <br>\n",
    "[0. Imports](#imports) <br>\n",
    "[1. MNIST dataset and scaling](#mnist) <br>\n",
    "[2. Principal Component Analysis (PCA)](#pca) <br>\n",
    "- [2a. Fit, transform, and visualize using training set](#pca_train) <br>\n",
    "- [2b. Transform and visualize test set](#pca_test) <br>\n",
    "- [2c. Variances and the inverse function](#pca_inverse) <br>\n",
    "- [2d. Fit and transform to 28 PCs](#pca_28) <br>\n",
    "- [2e. Fit and transform to 95% variance](#pca_95) <br>\n",
    "\n",
    "[3. t-distributed Stochastic Neighbor Embedding (t-SNE)](#tsne) <br>\n",
    "- [3a. Fit, transform, and visualize using training set](#tsne_train) <br>\n",
    "- [3b. Find an anomaly](#anomaly) <br>\n",
    "- [3c. Fit, transform, and visualize using 28 PCs](#tsne_28) <br>\n",
    "\n",
    "[4. Uniform Manifold Approximation and Projection (UMAP)](#umap) <br>\n",
    "- [4a. Fit, transform, and visualize using training set](#umap_train) <br>\n",
    "- [4b. Transform and visualize test set](#umap_test) <br>\n",
    "- [4c. Inverse function](#umap_inverse) <br>\n",
    "- [4d. UMAP using 28 PCs exercises](#exercises) <br>\n",
    "\n",
    "[5. Conclusions](#con) <br>\n",
    "[Appendix: TSVD](#append) <br>\n",
    "[Additional Resources](#add) <br>\n",
    "[About this Notebook](#about) <br>\n",
    "[Citations](#cite) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a id=\"intro\"></a>\n",
    "\n",
    "Analyzing and understanding high dimensional data is difficult, but we are a lot more equipped to analyze and understand 2-D and 3-D data. Dimensionality reduction is a subset of machine learning techniques that reduce high dimensional data to a low dimensional representation.  We can use dimensionality reduction to look for patterns in data to better understand its overall structure, which may be harder otherwise. By understanding the data's structure in a low dimensional space, we can make inferences of the data in the high dimensional space, such as what samples are similar and dissimilar. In addition, machine learning on high dimensional data is computationally expensive. By leveraging a low dimensional space, we can quickly train models without using every feature available to us.\n",
    "\n",
    "**The purpose of this notebook is to demonstrate principal component analysis (PCA), t-distributed stochastic neighbor embedding (t-SNE), and uniform manifold approximation and projection (UMAP) as dimensionality reduction techniques on the MNIST dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports <a id=\"imports\"></a>\n",
    "\n",
    "We use `numpy` for arrays, `matplotlib` for plotting, `tensorflow` for getting MNIST data, `sklearn` for PCA and t-SNE, and `umap` for UMAP.\n",
    "\n",
    "If you do not have some of the packages, please follow the conda installation guides:\n",
    "- [Numpy](https://numpy.org/install/)\n",
    "- [Matplotlib](https://matplotlib.org/stable/users/installing/index.html)\n",
    "- [Tensorflow](https://docs.anaconda.com/anaconda/user-guide/tasks/tensorflow/)\n",
    "- [Scikit-learn](https://scikit-learn.org/stable/install.html)\n",
    "- [UMAP](https://umap-learn.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MNIST dataset and scaling <a id=\"mnist\"></a>\n",
    "\n",
    "MNIST is a popular image data set of handwritten digits from 0 to 9. We use it to showcase the different dimensionality reduction techniques. Here are some qualities of the dataset:\n",
    "- 60k training samples\n",
    "- 10k testing samples\n",
    "- 10 classifications (digits 0-9)\n",
    "- 28x28 images\n",
    "- 8-bit gray scaled (0-255 pixel values)\n",
    "\n",
    "Why is MNIST such a good dataset to use for learning ML? \n",
    "- Relatively small images (only 784 features)\n",
    "- Relatively large data set (70k samples)\n",
    "- 10 unique well defined labels (all the digits are clearly different from each other)\n",
    "- very clean dataset (no noise)\n",
    "    - backgorund pixels are 0 and signal pixels are nearly 255 so it approximates a binomial distibution\n",
    "    - the digits are well centered, meaning pixels for similar parts of a digit should consistently be in the same vicinity\n",
    "    \n",
    "We retrieve our data using `tensorflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define some global variables and min-max normalize the images so pixels range between 0-1 (normalizing data is a common practice in machine learning). We also flatten our 28x28 images into a 784 feature arrays, in which each pixel is a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "x_train_size = x_train.shape[0]\n",
    "x_test_size = x_test.shape[0]\n",
    "x_length = x_train.shape[1]\n",
    "norm = x_train.max()\n",
    "\n",
    "# Scale images\n",
    "x_train_scale = x_train / norm\n",
    "x_test_scale = x_test / norm\n",
    "\n",
    "# Flatten arrays\n",
    "x_train_scale_flat = x_train_scale.reshape(x_train_size, x_length ** 2)\n",
    "x_test_scale_flat = x_test_scale.reshape(x_test_size, x_length ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the first 16 samples in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,4,figsize=[10,10])\n",
    "for i in range (4):\n",
    "    for j in range (4):\n",
    "        axs[i,j].imshow(x_train_scale[i*4+j])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Principal Component Analysis (PCA) <a id=\"pca\"></a>\n",
    "\n",
    "Principal component analysis [(PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis) is the first go-to method for dimensionality reduction because of its simplicity and linear nature. It's built off of linear algebra, mostly related to singular value decomposition (SVD). The goal of PCA is to find the axes of most variation and project the data onto those axes, which conserves global structure. Because it's just using linear algebra, it is an extremely precise embedding, meaning results generally will not change from different runs. It's also exceptionally fast, which is why practicioners use this first to explore data. In addition, fitting more components doesn't change the results of previous components, i.e., a 3-D reduction is the 2-D reduction with an added dimension. Furthermore, axes are fit in decreasing amounts of variation. That is to say the first principal component holds the most variation, the second principal component holds the second most variation, etc. Adding more components adds more variance by decreasing amounts. Here are some useful more complete resources:\n",
    "\n",
    "- [Stat Quest Main Ideas Video (6 minues, simple language)](https://www.youtube.com/watch?v=HMOI_lkzW08)\n",
    "- [Stat Quest Detailed Video (22 minutes, simple language)](https://www.youtube.com/watch?v=FgakZw6K1QQ&t=231s)\n",
    "- [Computerphile Video (20 minutes, intermediate lanuage)](https://www.youtube.com/watch?v=TJdH6rPA-TI)\n",
    "- [Steve Brunton Video (14 minutes, advanced language)](https://www.youtube.com/watch?v=fkf4IBRSeEc&t=645s)\n",
    "- [A Tutorial on Principal Component Analysis Paper](https://arxiv.org/pdf/1404.1100.pdf)\n",
    "\n",
    "\n",
    "There is also functional PCA [(FPCA)](https://en.wikipedia.org/wiki/Functional_principal_component_analysis), which can be used for time series. Instead of building eigenvectors to project data points to, FPCA builds eigenfunctions to project time series to. Here's the Python implementation if it's of interest: [`scikit-fda`](https://fda.readthedocs.io/en/latest/auto_examples/plot_fpca.html#sphx-glr-auto-examples-plot-fpca-py).\n",
    "\n",
    "### 2a. Fit, transform, and visualize using training set <a id=\"pca_train\"></a>\n",
    "\n",
    "We use [scikit-learn for PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html). We reduce to the first two principal components for simplicity. In addition, we set `whiten=True`, which normalizes the principal components to a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sklearn.decomposition.PCA(n_components=2, whiten=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit and transform the data from the input space to the \"PCA space\", or the reduced space formed from PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_pca = time()\n",
    "pca_mnist_train = pca.fit_transform(x_train_scale_flat)\n",
    "t1_pca = time()\n",
    "\n",
    "print ('Time spent fitting model: {:.4f} seconds'.format(t1_pca-t0_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the shape to make sure we have two principal components as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_mnist_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll plot the training set in the PCA space, where the x-axis is the first principal component, the y-axis is the second principal component, and each data point represents an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "plt.title('PCA using MNIST (training): unlabeled')\n",
    "plt.scatter(pca_mnist_train[:, 0], pca_mnist_train[:, 1], s=5, alpha=0.5)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting shape, but hard to tell if any meaningful groups formed. Let's color the plot by digit to get a better idea of where the digits are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "plt.title('PCA using MNIST (training): labeled')\n",
    "for i in range (10):\n",
    "    mask = y_train == i\n",
    "    plt.scatter(pca_mnist_train[:, 0][mask], pca_mnist_train[:, 1][mask], \n",
    "                s=5, alpha=0.5, label=i, color='C{}'.format(i))\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar digits clearly cluster together, but there is a good amount of overlap. Let's plot ten times by digit to get a better sense of the overlapping regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range (10):\n",
    "    # Plot digit\n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.title('PCA using MNIST (training): labeled {}'.format(i))\n",
    "    mask = y_train == i\n",
    "    plt.scatter(pca_mnist_train[:, 0][mask], pca_mnist_train[:, 1][mask], \n",
    "                s=5, alpha=0.5, label=i, color='C{}'.format(i))\n",
    "    # Plot transparent background\n",
    "    for j in range (10):\n",
    "        mask2 = y_train == j\n",
    "        plt.scatter(pca_mnist_train[:, 0][mask2], pca_mnist_train[:, 1][mask2], \n",
    "                    s=1, alpha=0.1, color='C{}'.format(j))\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could be convinced that a simple classification/clustering algorithm on just two digits in the PCA space would yield good results, illustrating the the 784-D input space is well represented in the 2-D PCA space. The clusters are somewhat interpratable as well:\n",
    "- 0 and 1 are the most distant clusters, which makes sense because they have no common features in the input space (0s are curvy and 1s are straight).\n",
    "- 4, 7, and 9 overlap, which makes sense because all these digits contain a straight line and a some feature at the top of the digit.\n",
    "- 2, 3, 5, 6, and 8 all overlap, which makes sense because all these digits contain a curve and are generally more \"complex\" than other digits.\n",
    "- 1 has a tight distribution, which makes sense because there are less degrees of freedom for drawing a 1.\n",
    "- 2 and 5 have wide distributions, which makes sense because there are many ways to draw a 2 and 5.\n",
    "\n",
    "It's nice that some of these small mental checks of the PCA space and where samples are embedded with respect to their classification are understandable, i.e., nothing about the embedding is too surprising.\n",
    "\n",
    "### 2b. Transform and visualize test set <a id=\"pca_test\"></a>\n",
    "\n",
    "To see if this representation is generalized, we transform the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_mnist_test = pca.transform(x_test_scale_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll plot the test set in the PCA space, with the training set as a transparent background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "for i in range (10):\n",
    "    plt.title('PCA using MNIST (test): labeled')\n",
    "    mask = y_train == i\n",
    "    plt.scatter(pca_mnist_train[:, 0][mask], pca_mnist_train[:, 1][mask], \n",
    "                s=1, alpha=0.1, color='C{}'.format(i))\n",
    "    mask2 = y_test == i\n",
    "    plt.scatter(pca_mnist_test[:, 0][mask2], pca_mnist_test[:, 1][mask2], \n",
    "                s=5, alpha=0.5, label=i, color='C{}'.format(i))\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, there is some overlap so let's plot by digit to clearly see the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (10):\n",
    "    # Plot digit\n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.title('PCA using MNIST (test): labeled {}'.format(i))\n",
    "    mask = y_test == i\n",
    "    plt.scatter(pca_mnist_test[:, 0][mask], pca_mnist_test[:, 1][mask], \n",
    "                s=5, alpha=0.5, label=i, color='C{}'.format(i))\n",
    "    # Plot transparent background\n",
    "    for j in range (10):\n",
    "        mask2 = y_train == j\n",
    "        plt.scatter(pca_mnist_train[:, 0][mask2], pca_mnist_train[:, 1][mask2], \n",
    "                    s=1, alpha=0.1, color='C{}'.format(j))\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The digits in the test set are reduced near their associated labels, meaning the PCA space is generalized.\n",
    "\n",
    "### 2c. Variances and the inverse function <a id=\"pca_inverse\"></a>\n",
    "\n",
    "Remember, PCA finds the axes of most variance within the data's input space and projects the data onto those axes. We can calculate the total percentage of variance the PCA space has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('First PC Variance: {:.4f}'.format(pca.explained_variance_ratio_[0]))\n",
    "print ('Second PC Variance: {:.4f}'.format(pca.explained_variance_ratio_[1]))\n",
    "print ('Total Variance: {:.4f}'.format(pca.explained_variance_ratio_.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first principal component contains 9.7% of the data's variance, and the second principal component contains 7.1% of the data's variance. The total variance contained is 16.8%.\n",
    "\n",
    "PCA also has an inverse transformation function that goes from the PCA space to original input space. The more variance contained, the better the inverse transformations are. Let's inverse transform the first 8 samples from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 8\n",
    "pca_mnist_inverse = pca.inverse_transform(pca_mnist_train[:subset]).reshape(subset, x_length, x_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot the input samples with the inverse samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, subset, figsize=[20, 5])\n",
    "for i in range (subset):\n",
    "    axs[0, i].imshow(x_train_scale[i])\n",
    "    axs[1, i].imshow(pca_mnist_inverse[i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the PCA space doesn't contain a lot of the data's variance, the inverse transforms are not that good. Most inverses do not look like their parent sample.\n",
    "\n",
    "Since we have an inverse function, we can also sample from the PCA space and inverse to generate \"new digits\", which will help us understand how MNIST is mapped onto the PCA space. \n",
    "\n",
    "First, we'll make a grid of points as our samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = -2, 4\n",
    "y_min, y_max = -3, 3\n",
    "n = 10\n",
    "pca_manifold = []\n",
    "for i in np.linspace(y_max,y_min,n):\n",
    "    for j in np.linspace(x_min,x_max,n):\n",
    "        pca_manifold.append([j, i])\n",
    "pca_manifold = np.array(pca_manifold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we inverse transform the grid points to the high dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_manifold_inverse = pca.inverse_transform(pca_manifold).reshape(n, n, x_length, x_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can plot the grid with each \"digit\" representing the inverse of a grid point near those coordinates, e.g., (-2,-1) in PCA space is mapped onto (-2,-1) on the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image with all inverses\n",
    "manifold = np.zeros((n*x_length, n*x_length))\n",
    "for i in range (n):\n",
    "    for j in range (n):\n",
    "        manifold[i*x_length:(i+1)*x_length, j*x_length:(j+1)*x_length] = pca_manifold_inverse[i, j]\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=[20,10])\n",
    "\n",
    "# Plot training set in PCA space\n",
    "axs[0].set_title('PCA using MNIST (training): labeled')\n",
    "for i in range (10):\n",
    "    mask = y_train == i\n",
    "    axs[0].scatter(pca_mnist_train[:, 0][mask], pca_mnist_train[:, 1][mask], \n",
    "                s=5, alpha=0.5, label=i, color='C{}'.format(i))\n",
    "axs[0].set_xlabel('PC1')\n",
    "axs[0].set_ylabel('PC2')\n",
    "axs[0].set_xlim(x_min, x_max)\n",
    "axs[0].set_ylim(y_min, y_max)\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot inverse grid\n",
    "axs[1].set_title('PCA using MNIST: manifold')\n",
    "axs[1].imshow(manifold, extent=[x_min,x_max,y_min,y_max])\n",
    "axs[1].set_xlabel('PC1')\n",
    "axs[1].set_ylabel('PC2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inverse grid hardly looks realistic, but the map reinforces that the PCA space in general represents our data:\n",
    "\n",
    "- on the bottom left (-2,-3), we have our 1s\n",
    "- on the bottom right (4,-3), we have our 0s\n",
    "- on the top left (-2,3), we have our 9s\n",
    "- on the top right (4,3), we have a combination of a 0 and a 9.\n",
    "    - the PCA space didn't have any samples originally there so the inverse function is trying its best to predict what might be there.\n",
    "\n",
    "### 2d. Fit and transform to 28 PCs <a id=\"pca_28\"></a>\n",
    "\n",
    "In order to learn a better representation, let's try keeping the first 28 principal components and seeing how well the inverse transformation is. **Note: the author likes to use the square root of the number of features (especially for square images) as a starting point for low dimensional representation, which is why here we choose 28.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_28 = sklearn.decomposition.PCA(n_components=28, whiten=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit and transform the samples to 28 principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_pca_28 = time()\n",
    "pca_28_mnist_train = pca_28.fit_transform(x_train_scale_flat)\n",
    "t1_pca_28 = time()\n",
    "\n",
    "print ('Time spent fitting model: {:.4f} seconds'.format(t1_pca_28-t0_pca_28))\n",
    "print ('Total Variance: {:.4f}'.format(pca_28.explained_variance_ratio_.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after adding another 26 principal components, PCA is still really fast. The total amount of variance contained in the first 28 principal components is 71.6%, which is much higher than the 2-D representation. To show fitting more components doesn't change the results of the previous components, we plot a histogram of the differences between the first principal components of the 2-D and 28-D spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Difference Histogram')\n",
    "plt.hist(pca_mnist_train[:, 0] - pca_28_mnist_train[:, 0], bins=100)\n",
    "plt.xlabel('pca - pca_28')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The differences are negligible (~$10^{-5}$) most likely due to floating point precision. \n",
    "\n",
    "Let's replot the same samples as before with their 28-component inverses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 8\n",
    "pca_28_mnist_inverse = pca_28.inverse_transform(pca_28_mnist_train[:subset]).reshape(subset, x_length, x_length)\n",
    "\n",
    "fig, axs = plt.subplots(2, subset, figsize=[20, 5])\n",
    "for i in range (subset):\n",
    "    axs[0, i].imshow(x_train_scale[i])\n",
    "    axs[1, i].imshow(pca_28_mnist_inverse[i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inverses are a bit better and can for the most part be recognized as their parent sample. However, the inverses are a little blurry/noisy.\n",
    "\n",
    "### 2e. Fit and transform to 95% variance <a id=\"pca_95\"></a>\n",
    "\n",
    "Let's try keeping the number of components that contains 95% of the variance, which is a common heuristic. We can do this by using the portion we want as the number of components in `PCA()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "pca_95 = sklearn.decomposition.PCA(n_components=0.95, whiten=True)\n",
    "\n",
    "# Fit\n",
    "pca_95_mnist_train = pca_95.fit_transform(x_train_scale_flat)\n",
    "print ('Number of PCs: ', pca_95_mnist_train.shape[1])\n",
    "print ('Total Variance: {:.4f}'.format(pca_95.explained_variance_ratio_.sum()))\n",
    "\n",
    "# Evaluate inverses\n",
    "subset = 8\n",
    "pca_95_mnist_inverse = pca_95.inverse_transform(pca_95_mnist_train[:subset]).reshape(subset, x_length, x_length)\n",
    "\n",
    "# Plot inverses\n",
    "fig, axs = plt.subplots(2, subset, figsize=[20, 5])\n",
    "for i in range (subset):\n",
    "    axs[0, i].imshow(x_train_scale[i])\n",
    "    axs[1, i].imshow(pca_95_mnist_inverse[i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 154-D inverses are almost identical, with just some noise around the digits.\n",
    "\n",
    "Since we have a lot of components, we can plot the components by their ratios to see how much variance each component is adding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize=[20,10])\n",
    "\n",
    "axs[0].set_title('PCA 154 Variance Plot')\n",
    "axs[0].scatter(np.arange(pca_95_mnist_train.shape[1]), pca_95.explained_variance_ratio_)\n",
    "axs[0].set_xlabel('Component')\n",
    "axs[0].set_ylabel('Variance Ratio')\n",
    "\n",
    "axs[1].set_title('PCA 154 Variance Plot (Log Scale)')\n",
    "axs[1].scatter(np.arange(pca_95_mnist_train.shape[1]), pca_95.explained_variance_ratio_)\n",
    "axs[1].set_xlabel('Component')\n",
    "axs[1].set_ylabel('Variance Ratio')\n",
    "axs[1].set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that as components get added, the amount of variance they're adding decreases.\n",
    "\n",
    "If you remember the first embedding plot we made, all of the digits were essentially in one big blob. These next two methods perform a lot better in placing similar samples close to each other and distinguishing groups of data with boundaries in the embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. t-distributed Stochastic Neighbor Embedding (t-SNE) <a id=\"tsne\"></a>\n",
    "\n",
    "t-distributed stochastic neighbor embedding [(t-SNE)](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) is a nonlinear dimensionality reduction method, mostly used as a visualization tool. Here's the `scikit-learn` definition:\n",
    "\n",
    "    t-SNE is a tool to visualize high-dimensional data. It converts similarities between data points to joint\n",
    "    probabilities and tries to minimize the Kullback-Leibler divergence between the joint probabilities of the low\n",
    "    dimensional embedding and the high-dimensional data. t-SNE has a cost function that is not convex, i.e. with\n",
    "    different initializations we can get different results.\n",
    "\n",
    "It is extremely useful for exploratory data analysis (EDA) since its purpose is to put similar samples near each other, i.e., there's an emphasis on local structure. That being said, the global structure is not well represented and the distances between far samples in the embedded space are not similar to their respective distances in the input space.\n",
    " \n",
    "It can only fit data to a reduced space, i.e., it can't predict new samples. This weakness means if you recieved more data, the embedding would have to be fit again entirely. One could in theory [train a neural network to learn the embedding](https://lvdmaaten.github.io/publications/papers/AISTATS_2009.pdf), but that is beyond the scope of this tutorial. Another weakness is that it is relatively slow compared to PCA. Here are some useful more complete resources:\n",
    "\n",
    "- [Stat Quest Video (12 minutes, simple language)](https://www.youtube.com/watch?v=NEaUSP4YerM)\n",
    "- [Visualizing Data using t-SNE Talk (55 minutes, advanced language)](https://www.youtube.com/watch?v=RJVL80Gg3lA&t=15s)\n",
    "- [t-SNE Original Paper](https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf)\n",
    "\n",
    "### 3a. Fit, transform, and visualize using training set <a id=\"tsne_train\"></a>\n",
    "\n",
    "We also use [scikit-learn for t-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). Since the method is stochastic, different runs will have different results. The main hyperparameter for t-SNE is perplexity, which is similar to the number of nearest neighbors used for the embedding. Results are very sensitive to perplexity and changing it by a little can cause drastic differences in the reduced space. Here, we reduce to two components and choose the default perplexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = sklearn.manifold.TSNE(n_components=2, perplexity=30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fit and transform the training set to the \"t-SNE space\", or the reduced space formed from t-SNE. **Warning: this may take several minutes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_tsne = time()\n",
    "tsne_mnist_train = tsne.fit_transform(x_train_scale_flat)\n",
    "t1_tsne = time()\n",
    "\n",
    "print ('Time spent fitting model: {:.4f} seconds'.format(t1_tsne-t0_tsne))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparably, t-SNE is a lot slower than PCA. Let's check the shape to make sure we have two components as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_mnist_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the training set in the t-SNE space. The x and y axes are meaningless, and the focus of the analysis should be on the samples' locations with respect to their neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "plt.title('t-SNE using MNIST (training): unlabeled')\n",
    "plt.scatter(tsne_mnist_train[:, 0], tsne_mnist_train[:, 1], s=5, alpha=0.5)\n",
    "plt.xlabel('TSNE1')\n",
    "plt.ylabel('TSNE2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By eye, there is arguably 11 distinct clusters, which is a lot better than PCA. Let's color the plot by digit to see where the digits are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "plt.title('t-SNE using MNIST (training): labeled')\n",
    "for i in range (10):\n",
    "    mask = y_train == i\n",
    "    plt.scatter(tsne_mnist_train[:, 0][mask], tsne_mnist_train[:, 1][mask], \n",
    "                s=5, alpha=0.5, label=i, color='C{}'.format(i))\n",
    "plt.xlabel('TSNE1')\n",
    "plt.ylabel('TSNE2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the clusters are independent with small margins dividing each one up. Let's plot by digit to get some finer details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range (10):\n",
    "    # Plot digit\n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.title('t-SNE using MNIST (training): labeled')\n",
    "    mask = y_train == i\n",
    "    plt.scatter(tsne_mnist_train[:, 0][mask], tsne_mnist_train[:, 1][mask], \n",
    "                s=5, alpha=0.5, label=i, color='C{}'.format(i))\n",
    "    # Plot background\n",
    "    for j in range (10):\n",
    "        mask2 = y_train == j\n",
    "        plt.scatter(tsne_mnist_train[:, 0][mask2], tsne_mnist_train[:, 1][mask2], \n",
    "                    s=1, alpha=0.1, color='C{}'.format(j))\n",
    "    plt.xlabel('TSNE1')\n",
    "    plt.ylabel('TSNE2')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could be convinced that a simple classification/clustering algorithm on several digits in the t-SNE space would produce good results, illustrating the the 784-D input space is well represented in the 2-D t-SNE space. In addition, t-SNE far outperforms PCA in not overlapping several digits and forming distinct groups. The 3 cluster (red) is split, indicating there could be two different local strctures of 3s or the model needed more time to run (see `n_iter` in documentation).\n",
    "\n",
    "### 3b. Find an anomaly <a id=\"anomaly\"></a>\n",
    "\n",
    "The \"anomalies\", or samples that aren't part of their respective digit clusters, had trouble embedding to their cluster either because they are true anomalies or because the hyperparameters we chose weren't optimal enough. Let's find an anomaly and see if there's a reason why it joined a specific cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a 9 with the greatest x coordinate as an anomaly\n",
    "num = 9\n",
    "index = np.where(tsne_mnist_train[y_train==num][:, 0].max() == tsne_mnist_train)[0][0]\n",
    "\n",
    "# Plot t-SNE space\n",
    "fig, axs = plt.subplots(1,2,figsize=[16,8])\n",
    "for i in range (10):\n",
    "    mask = y_train == i\n",
    "    axs[0].scatter(tsne_mnist_train[:, 0][mask], tsne_mnist_train[:, 1][mask], \n",
    "                s=1, alpha=0.1, label=i, color='C{}'.format(i))\n",
    "\n",
    "# Plot the anomaly in t-SNE space as black\n",
    "axs[0].scatter(tsne_mnist_train[index][0], tsne_mnist_train[index][1], s=10, color='k', label='anomaly')\n",
    "axs[0].set_title('t-SNE using MNIST (training): labeled')\n",
    "axs[0].set_xlabel('TSNE1')\n",
    "axs[0].set_ylabel('TSNE2')\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot the anomaly\n",
    "axs[1].imshow(x_train_scale[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This 9 (black) was grouped with the 0s (dark blue). Even though the anomaly 9 has a small stem, it could easily be mistaken as a 0.\n",
    "\n",
    "### 3c. Fit, transform, and visualize using 28 PCs <a id=\"tsne_28\"></a>\n",
    "\n",
    "In practice, it is recommended to use another dimensionality reduction technique, e.g. PCA, before t-SNE to reduce noise and computation time. Using a smaller number of features that well represent the original data set will suffice for data visualization. We use the same hyperparameters as before for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_28 = sklearn.manifold.TSNE(n_components=2, perplexity=30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the first 28 principal components of the training set from earlier as features to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_tsne_28 = time()\n",
    "tsne_28_mnist_train = tsne.fit_transform(pca_28_mnist_train)\n",
    "t1_tsne_28 = time()\n",
    "\n",
    "print ('Time spent fitting model: {:.4f} seconds'.format(t1_tsne_28-t0_tsne_28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 28 features instead of 784 slightly decreased the amount of time t-SNE took to model. We could imagine extremely high dimensional data (>10k features) would benefit more from an initial reduction.\n",
    "\n",
    "Let's plot the new embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "for i in range (10):\n",
    "    plt.title('t-SNE using 28 MNIST PCs (training): labeled')\n",
    "    mask = y_train == i\n",
    "    plt.scatter(tsne_28_mnist_train[:, 0][mask], tsne_28_mnist_train[:, 1][mask], \n",
    "                s=5, alpha=0.5, label=i, color='C{}'.format(i))\n",
    "plt.xlabel('TSNE1')\n",
    "plt.ylabel('TSNE2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the noise was reduced using PCA, the 3s cluster (red) is not split anymore. Now we have 10 distinct clusters, one for each digit. There are still some anomalies, which we can visualize by plotting the digits individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (10):\n",
    "    # Plot digit\n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.title('t-SNE using 28 MNIST PCs (training): labeled')\n",
    "    mask = y_train == i\n",
    "    plt.scatter(tsne_28_mnist_train[:, 0][mask], tsne_28_mnist_train[:, 1][mask], \n",
    "                s=5, alpha=0.5, label=i, color='C{}'.format(i))\n",
    "    # Plot background\n",
    "    for j in range (10):\n",
    "        mask2 = y_train == j\n",
    "        plt.scatter(tsne_28_mnist_train[:, 0][mask2], tsne_28_mnist_train[:, 1][mask2], \n",
    "                    s=1, alpha=0.1, color='C{}'.format(j))\n",
    "    plt.xlabel('TSNE1')\n",
    "    plt.ylabel('TSNE2')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-SNE overall outperforms PCA in local structure connectivity with similar samples being close to each other in the reduced space. It can also distinctly form clusters of digits either using the original features or principal components. However, some drawbacks include computational complexity, no prediction after training, and no inverse function from the reduced space back to the original space. For these reasons, t-SNE is more useful as a data visualization tool. Thankfully, our last method addresses these drawbacks with the added benefit of focusing on global structure as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Uniform Manifold Approximation and Projection (UMAP) <a id=\"umap\"></a>\n",
    "\n",
    "Uniform manifold approximation and projection [(UMAP)](https://github.com/lmcinnes/umap) is a nonlinear dimensionality reduction technique that has gained widespread use and popularity since its conception in 2018. UMAP constructs neighbor graphs in a high dimension and projects that graph to a low dimension. It does so by making three assumptions:\n",
    "\n",
    "- The data is uniformly distributed on Riemannian manifold;\n",
    "- The Riemannian metric is locally constant (or can be approximated as such);\n",
    "- The manifold is locally connected.\n",
    "\n",
    "UMAP aims to conserve both local and global structure; the distances between similar samples in the high dimensional space are consistent with those distances in the low dimensional space, and the distances between clusters formed here are more meaningful than in t-SNE. Because of this, clusters will form and try to distance themselves away from each other, unlike t-SNE. The mathematical theory behind UMAP is intense and is beyond the scope of the tutorial, but the theory makes the algorithm robust as a proof of concept. \n",
    "\n",
    "In addition, it's pretty fast with its computational complexity just above PCA, but far below t-SNE. Furthermore, data can be projected into the reduced space after training, i.e., prediction of new data is possible. Lastly, there exists an inverse function between the low dimensional space and high dimensional space. Here are some useful more complete resources:\n",
    "\n",
    "- [StatQuest UMAP: Main Ideas (19 minutes, simple language)](https://www.youtube.com/watch?v=eN0wFzBA4Sc)\n",
    "- [StatQuest UMAP: Mathematical Details (16 minutes, simple language)](https://www.youtube.com/watch?v=jth4kEvJ3P8)\n",
    "- [AI Coffee Bean Video (9 minutes, intermediate language)](https://www.youtube.com/watch?v=6BPl81wGGP8)\n",
    "- [McInnes (author) Scipy Talk (26 minutes, advanced language)](https://www.youtube.com/watch?v=nq6iPZVUxZU&t=843s)\n",
    "- [UMAP original paper](https://arxiv.org/pdf/1802.03426.pdf)\n",
    "- [Understanding UMAP (article)](https://pair-code.github.io/understanding-umap/)\n",
    "\n",
    "### 4a. Fit, transform, and visualize using training set <a id=\"umap_train\"></a>\n",
    "\n",
    "We use a [Python implementation of UMAP](https://umap-learn.readthedocs.io/en/latest/) that is built similar to `sklearn`. The two main hyperparameters for this algorithm are `n_neighbors` and `min_dist`. The former determines the number of neighbors used for the local approximation, and larger values conserve more global structure. The later determines how tight the data is in the reduced space, and smaller values conserve more local structure. Tuning these hyperparameters smoothly changes the overall embedding. We reduce to two components and choose the default hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "umap = UMAP(n_components=2, n_neighbors=15, min_dist=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like PCA and t-SNE, we fit and transform the training data to the \"UMAP space\", or the reduced space formed from UMAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_umap = time()\n",
    "umap_mnist_train = umap.fit_transform(x_train_scale_flat)\n",
    "t1_umap = time()\n",
    "\n",
    "print ('Time spent fitting model: {:.4f} seconds'.format(t1_umap-t0_umap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not as fast as PCA, but way faster than t-SNE. Let's check the shape to make sure we have two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_mnist_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the training set in the UMAP space. Like t-SNE, the axes are arbitrary and analysis should focus on samples' locations with respect to their neighbors and clusters' locations with respect to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "plt.title('UMAP using MNIST (training): unlabeled')\n",
    "plt.scatter(umap_mnist_train[:, 0], umap_mnist_train[:, 1], s=5, alpha=0.5)\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are clearly 10 distinct clusters with a good amount of separation between them. Let's color the plot so we can see where each digit lies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "plt.title('UMAP using MNIST (training): labeled')\n",
    "for i in range (10):\n",
    "    mask = y_train == i\n",
    "    plt.scatter(umap_mnist_train[:, 0][mask], umap_mnist_train[:, 1][mask], \n",
    "                s=5, alpha=0.5, label=i, color='C{}'.format(i))\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the digits formed their own groups. Since there are some \"anomalies\", let's plot by digit to get finer details of where they lie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (10):\n",
    "    # Plot digit\n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.title('UMAP using MNIST (training): labeled')\n",
    "    mask = y_train == i\n",
    "    plt.scatter(umap_mnist_train[:, 0][mask], umap_mnist_train[:, 1][mask], \n",
    "                s=5, alpha=0.5, label=i, color='C{}'.format(i))\n",
    "    # Plot background\n",
    "    for j in range (10):\n",
    "        mask2 = y_train == j\n",
    "        plt.scatter(umap_mnist_train[:, 0][mask2], umap_mnist_train[:, 1][mask2], \n",
    "                    s=1, alpha=0.1, color='C{}'.format(j))\n",
    "    plt.xlabel('UMAP1')\n",
    "    plt.ylabel('UMAP2')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could be convinced that a simple classification/clustering algorithm on all the digits in the UMAP space would yield excellent results, illustrating the the 784-D input space is well represented in the 2-D UMAP space. The clusters are also relatively dense compared to PCA and t-SNE. The clusters are interpratable as well:\n",
    "\n",
    "- 0 and 1 remain distant as we saw in PCA.\n",
    "- 4, 7, and 9 remain close like in PCA.\n",
    "- 2, 5, and 8 have the most overlap as we saw in t-SNE.\n",
    "\n",
    "### 4b. Transform and visualize test set <a id=\"umap_test\"></a>\n",
    "\n",
    "To see if this representation is generalized, we transform the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_mnist_test = umap.transform(x_test_scale_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the test set in the UMAP space with the training set as a transparent background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "plt.title('UMAP using MNIST (test): labeled')\n",
    "for i in range (10):\n",
    "    mask = y_train == i\n",
    "    plt.scatter(umap_mnist_train[:, 0][mask], umap_mnist_train[:, 1][mask], \n",
    "                s=1, alpha=0.1, color='C{}'.format(i))\n",
    "    mask2 = y_test == i\n",
    "    plt.scatter(umap_mnist_test[:, 0][mask2], umap_mnist_test[:, 1][mask2], \n",
    "                s=5, alpha=0.5, label=i, color='C{}'.format(i))\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set nicely transforms to their associated digits in the UMAP space. To see the test set anomalies, we plot by digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (10):\n",
    "    # Plot digit\n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.title('UMAP using MNIST (test): labeled')\n",
    "    mask = y_test == i\n",
    "    plt.scatter(umap_mnist_test[:, 0][mask], umap_mnist_test[:, 1][mask], \n",
    "                s=5, alpha=0.5, label=i, color='C{}'.format(i))\n",
    "    # Plot background\n",
    "    for j in range (10):\n",
    "        mask2 = y_train == j\n",
    "        plt.scatter(umap_mnist_train[:, 0][mask2], umap_mnist_train[:, 1][mask2], \n",
    "                    s=1, alpha=0.1, color='C{}'.format(j))\n",
    "    plt.xlabel('UMAP1')\n",
    "    plt.ylabel('UMAP2')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c. Inverse function <a id=\"umap_inverse\"></a>\n",
    "\n",
    "As mentioned, UMAP has an inverse function going from the low dimensional space to the original input space. Here, we inverse transform the first 8 samples of the training set. **Note: the inverse transformation takes longer than PCA's inverse.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 8\n",
    "umap_mnist_inverse = umap.inverse_transform(umap_mnist_train[:subset]).reshape(subset, x_length, x_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the original samples with their inverses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, subset, figsize=[20, 5])\n",
    "for i in range (subset):\n",
    "    axs[0, i].imshow(x_train_scale[i])\n",
    "    axs[1, i].imshow(umap_mnist_inverse[i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with just a 2-D representation, the inverses are pretty convincing and outperforms PCA in this regard for low dimensional representation. However, one of UMAPs weaknesses is the inverse function scales poorly with increased reduced space. As PCA's inverses increase in quality (as we saw from 2-D to 154-D), UMAPs inverses decrease in quality and becomes too computationally expensive at dimensions higher than 3-D, making the inverse function essentially useless after that.\n",
    "\n",
    "In comparison with PCA, we evaluate the inverse function on a grid of points in the UMAP space to visualize how the inverses smoothly change. First, we make a grid of points as our samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_min, x_max = -6, 16\n",
    "y_min, y_max = -6, 16\n",
    "n = 15\n",
    "umap_manifold = []\n",
    "for i in np.linspace(y_max,y_min,n):\n",
    "    for j in np.linspace(x_min,x_max,n):\n",
    "        umap_manifold.append([j, i])\n",
    "umap_manifold = np.array(umap_manifold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we inverse transform the grid points to the high dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_manifold_inverse = umap.inverse_transform(umap_manifold).reshape(n, n, x_length, x_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we plot the manifold of the UMAP space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image of inverses\n",
    "manifold = np.zeros((n*x_length, n*x_length))\n",
    "for i in range (n):\n",
    "    for j in range (n):\n",
    "        manifold[i*x_length:(i+1)*x_length, j*x_length:(j+1)*x_length] = umap_manifold_inverse[i, j]\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=[20,10])\n",
    "\n",
    "# Plot UMAP space\n",
    "axs[0].set_title('UMAP using MNIST (training): labeled')\n",
    "for i in range (10):\n",
    "    mask = y_train == i\n",
    "    axs[0].scatter(umap_mnist_train[:, 0][mask], umap_mnist_train[:, 1][mask], \n",
    "                s=5, alpha=0.5, label=i, color='C{}'.format(i))\n",
    "axs[0].set_xlabel('UMAP1')\n",
    "axs[0].set_ylabel('UMAP2')\n",
    "axs[0].set_xlim(x_min, x_max)\n",
    "axs[0].set_ylim(y_min, y_max)\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot inverses\n",
    "axs[1].set_title('UMAP using MNIST: manifold')\n",
    "axs[1].imshow(manifold, extent=[x_min,x_max,y_min,y_max])\n",
    "axs[1].set_xlabel('UMAP1')\n",
    "axs[1].set_ylabel('UMAP2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UMAP manifold is a lot more interesting than the PCA manifold. For starters, the blank spaces inverse transforms to an 8 so for some reason it takes that digit to be a \"default\" guess. Most clusters inverse to the labeled digit, e.g., points near the 0 cluster (~13.5, 7.5) inverse transforms to a 0. The 4, 7 and 9 clusters smoothly transition to each other, reinforcing the similarities the digits have.\n",
    "\n",
    "### 4d. UMAP using 28 PCs exercises <a id=\"exercises\"></a>\n",
    "\n",
    "It is also recommended to use another dimensionality reduction technique before UMAP for the same reasons as t-SNE. We leave that as an exercise for the reader.\n",
    "\n",
    "1. Define a UMAP model using the same hyperparameters as before: \n",
    "    - `umap_28 = UMAP(n_components=2, n_neighbors=15, min_dist=0.1, random_state=42)`\n",
    "2. Fit, transform, and visualize using 28 PCs:\n",
    "    - `umap_28_mnist_train = umap_28.fit_transform(pca_28_mnist_train)`\n",
    "3. Transform and visualize test set by:\n",
    "    - 3a. Transforming the test set to 28-D PCA space\n",
    "        - `pca_28_mnist_test = pca_28.transform(x_test_scale_flat)`\n",
    "    - 3b. Transforming from PCA space to UMAP space **(Hint: Reuse the plotting code and replace with the `umap_28` objects accordingly)**\n",
    "        - `umap_28_mnist_test = umap_28.transform(pca_28_mnist_test)`\n",
    "4. Visualize inverses by:\n",
    "    - 4a. Inverse transforming 8 samples from UMAP space to PCA space\n",
    "        - `umap_28_mnist_inverse = umap_28.inverse_transform(umap_28_mnist_train[:8])`\n",
    "    - 4b. Inverse transforming those samples from PCA space to input space **(Hint: Reuse the plotting code from `pca_28` objects)**\n",
    "        - `pca_28_mnist_inverse = pca_28.inverse_transform(umap_28_mnist_inverse).reshape(8,x_length,x_length)`\n",
    "    - if successful, if the PCA reconstructions are comparable to the original samples, then UMAP well represents the PCA space\n",
    "5. Analyze an anomaly as in [Section 3b.](#anomaly) **(Hint: Reuse the plotting code and replace with the `umap_28` objects accordingly)**\n",
    "\n",
    "Training may take a similar amount of time, but the UMAP spaces should be pretty similar between using the original input pixels and principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusions <a id=\"con\"></a>\n",
    "\n",
    "Dimensionality reduction is an excellent tool for discovering structure in high dimensional data. Principal component analysis is a fast linear algorithm that projects data onto axes of most variance, preserving global structure. t-distributed stochastic neighbor embedding is a slower nonlinear algorithm that reduces the similarities of neighbors in a high dimensional space to a low dimensional space, preserving local structure. Uniform manifold approximation and projection is a relatively fast algorithm that projects graphs in a high dimensional space to a low dimensional space, preserving a mix of global and local structure. There are many dimensionality reduction techniques, but using these three in unison is a substantial start to any machine learning based exploratory data analysis.\n",
    "\n",
    "**Thank you and congratulations for completing the notebook!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time spent for each model\n",
    "print ('Time spent fitting PCA: {:.4f} seconds'.format(t1_pca-t0_pca))\n",
    "print ('Time spent fitting PCA_28: {:.4f} seconds'.format(t1_pca_28-t0_pca_28))\n",
    "print ('Time spent fitting t-SNE: {:.4f} seconds'.format(t1_tsne-t0_tsne))\n",
    "print ('Time spent fitting t-SNE_28: {:.4f} seconds'.format(t1_tsne_28-t0_tsne_28))\n",
    "print ('Time spent fitting UMAP: {:.4f} seconds'.format(t1_umap-t0_umap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: TSVD <a id=\"append\"></a>\n",
    "\n",
    "There is a lot of debate of how to choose the optimal number of principal components in PCA. Ideally, we want to choose the number of components that maximizes signal and minimizes noise. Most data sets do not need to contain 95% of the variance since a lot of that variance is noise. The easy answer is everything is data specific, which is true, but there are various optimizations for choosing the number of components. One such method is [optimal truncated singular value decomposition](https://arxiv.org/pdf/1305.5870.pdf). By making some assumptions about the data's noise, one can calculate the number of components theoretically needed to remove a majority of the noise. Here are some videos that explain the method:\n",
    "\n",
    "- [Singular Value Decomposition Overview](https://www.youtube.com/watch?v=gXbThCXjZFM)\n",
    "- [SVD and Optimal Truncation](https://www.youtube.com/watch?v=9vJDjkx825k&t=3s)\n",
    "- [Optimal TSVD (Python)](https://www.youtube.com/watch?v=epoHE2rex0g&t=326s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources <a id=\"add\"></a>\n",
    "\n",
    "Machine learning is a dense and rapidly evolving field of study. Becoming an expert takes years of practice and patience, but hopefully this notebook brought you closer in that direction. Here are some of the author's favorite resources for learning about machine learning and data science:\n",
    "\n",
    "- [Google Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/ml-intro)\n",
    "- [scikit-learn Python Library](https://scikit-learn.org/stable/index.html) (go-to for most ML algorithms besides neural networks)\n",
    "- [StatQuest YouTube Channel](https://www.youtube.com/c/joshstarmer)\n",
    "- [DeepLearningAI YouTube Channel](https://www.youtube.com/c/Deeplearningai/videos)\n",
    "- [Towards Data Science](https://towardsdatascience.com/) (articles about data science and machine learning, some involving example blocks of code)\n",
    "- Advance searching [arxiv](https://arxiv.org/search/advanced) (e.g. search term \"machine learning\" in Abstract for Subject astro-ph) to see what others are doing currently\n",
    "- Google, YouTube, and Wikipedia in general\n",
    "\n",
    "## About this Notebook <a id=\"about\"></a>\n",
    "\n",
    "**Author:** Fred Dauphin, DeepWFC3\n",
    "\n",
    "**Updated on:** 2023-02-08\n",
    "\n",
    "## Citations <a id=\"cite\"></a>\n",
    "\n",
    "If you use `numpy`, `matplotlib`, `sklearn`, or `umap` for published research, please cite the authors. Follow these links for more information about citing `numpy`, `matplotlib`, `sklearn`, and `umap`:\n",
    "\n",
    "* [Citing `numpy`](https://numpy.org/doc/stable/license.html)\n",
    "* [Citing `matplotlib`](https://matplotlib.org/stable/users/project/license.html#:~:text=Matplotlib%20only%20uses%20BSD%20compatible,are%20acceptable%20in%20matplotlib%20toolkits.)\n",
    "* [Citing `sklearn`](https://scikit-learn.org/stable/about.html#citing-scikit-learn)\n",
    "* [Citing `umap`](https://github.com/lmcinnes/umap/blob/master/LICENSE.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "[Top of Page](#title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
